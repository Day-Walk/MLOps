import os
import json
import httpx
import re
import asyncio
import threading
from urllib.parse import quote
from typing import List, Dict, Any
import functools
from dotenv import load_dotenv

from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.callbacks import StdOutCallbackHandler
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool
from langchain_community.vectorstores import Chroma

load_dotenv()

class LangchainAgentService:
    def __init__(self, openai_api_key: str):
        if not openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        os.environ["OPENAI_API_KEY"] = openai_api_key
        
        self.llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.model_bge = HuggingFaceEmbeddings(
            model_name="upskyy/bge-m3-korean",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # ChromaDB ë¡œë“œ
        chroma_db_path = os.getenv("VECTORDB_PATH")
        if not chroma_db_path or not os.path.exists(chroma_db_path):
            raise FileNotFoundError(f"ChromaDB ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chroma_db_path}")
        self.chroma_bge = Chroma(
            persist_directory=chroma_db_path,
            embedding_function=self.model_bge
        )
        print("--- ChromaDB ë¡œë“œ ì™„ë£Œ ---")
        
        self.tools = [
            self._create_combined_search_tool(),
            self._create_congestion_tool()
        ]
        self.prompt = self._create_prompt_template()
        self.user_memories = {}
        self._lock = threading.Lock()

    def _create_combined_search_tool(self):
        @tool
        async def search_course(query: str, region: str, categories: List[str]) -> List[Dict[str, Any]]:
            """
            ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ì—­ê³¼ ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì¥ì†Œë¥¼ ê²€ìƒ‰í•˜ê³ ,
            ìƒì„¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¥ì†Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í†µí•© ê²€ìƒ‰ ë„êµ¬ì…ë‹ˆë‹¤.

            ì´ ë„êµ¬ëŠ” ë‘ ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤:
            1. 'ì§€ì—­(region)'ê³¼ 'ì¹´í…Œê³ ë¦¬(categories)'ë¡œ ì¥ì†Œ UUID ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            2. ê°€ì ¸ì˜¨ UUID ëª©ë¡ê³¼ `query`ì—ì„œ ì§€ì—­ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì œì™¸í•œ ë¬¸ìì—´ì„ ì‚¬ìš©í•´ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìƒì„¸ ì •ë³´ë¥¼ í•„í„°ë§í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.

            Args:
                query (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì „ì²´ ì¿¼ë¦¬ (ì˜ˆ: 'í™ëŒ€ì—ì„œ ê°ì„± ì¹´í˜ ê°”ë‹¤ê°€ ì „ì‹œ ë³´ëŠ” ì½”ìŠ¤ ì¶”ì²œ')
                region (str): ì‚¬ìš©ìê°€ ëª…ì‹œí•œ ì§€ì—­ëª… (ì˜ˆ: 'ê°•ë‚¨', 'í™ëŒ€', 'ì¢…ë¡œ3ê°€ì—­')
                categories (list of str): ê²€ìƒ‰í•  ì¥ì†Œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì…ë‹ˆë‹¤.
                ì‚¬ìš© ê°€ëŠ¥í•œ ì „ì²´ ì¹´í…Œê³ ë¦¬: 'ì „ì‹œê´€', 'ê¸°ë…ê´€', 'ì „ë¬¸ë§¤ì¥/ìƒê°€', '5ì¼ì¥', 'íŠ¹ì‚°ë¬¼íŒë§¤ì ', 'ë°±í™”ì ', 'ìƒì„¤ì‹œì¥', 'ë¬¸í™”ì „ìˆ˜ì‹œì„¤', 'ë¬¸í™”ì›', 'ì„œì–‘ì‹', 'ê±´ì¶•/ì¡°í˜•ë¬¼', 'ìŒì‹ì &ì¹´í˜', 'ë°•ë¬¼ê´€', 'ì»¨ë²¤ì…˜ì„¼í„°', 'ì—­ì‚¬ê´€ê´‘ì§€', 'ë³µí•© ë ˆí¬ì¸ ', 'ê³µì˜ˆ/ê³µë°©', 'ì´ìƒ‰ìŒì‹ì ', 'ì˜í™”ê´€', 'ì‚°ì—…ê´€ê´‘ì§€', 'ì¤‘ì‹', 'ë¬¸í™”ì‹œì„¤', 'ì‡¼í•‘', 'ìˆ˜ìƒ ë ˆí¬ì¸ ', 'ê´€ê´‘ì§€', 'ìœ¡ìƒ ë ˆí¬ì¸ ', 'í•™êµ', 'ê´€ê´‘ìì›', 'ìŠ¤í‚¤(ë³´ë“œ) ë Œíƒˆìƒµ', 'ëŒ€í˜•ì„œì ', 'íœ´ì–‘ê´€ê´‘ì§€', 'ì™¸êµ­ë¬¸í™”ì›', 'ìì—°ê´€ê´‘ì§€', 'ë ˆí¬ì¸ ', 'í•œì‹', 'ì¼ì‹', 'ë„ì„œê´€', 'ì²´í—˜ê´€ê´‘ì§€', 'ì¹´í˜/ì „í†µì°»ì§‘', 'ë©´ì„¸ì ', 'ê³µì—°ì¥', 'ë¯¸ìˆ ê´€/í™”ë‘'

            Returns:
                list: í•„í„°ë§ëœ ì¥ì†Œ ì •ë³´ ë¦¬ìŠ¤íŠ¸. ê° ì¥ì†ŒëŠ” ìƒì„¸ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
                      (ì˜ˆ: [{'name': 'OOì¹´í˜', 'address': 'ì„œìš¸...', ...}, ...])
            """
            # 1. Elastic Search to get UUIDs
            if not region or not categories:
                return []

            print(f"--- ì—˜ë¼ìŠ¤í‹± ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ë³„ í˜¸ì¶œ): region={region}, categories={tuple(sorted(categories))} ---")

            region_encoded = quote(region)
            all_place_uuids = set()

            async with httpx.AsyncClient() as client:
                tasks = []
                for category in categories:
                    category_encoded = quote(category)
                    url = f"http://15.164.50.188:9201/api/place/search/llm-tool?region={region_encoded}&categories={category_encoded}"
                    tasks.append(client.get(url, timeout=10))

                api_responses = await asyncio.gather(*tasks, return_exceptions=True)

                for response in api_responses:
                    if isinstance(response, httpx.Response):
                        try:
                            response.raise_for_status()
                            response_json = response.json()
                            uuids = response_json.get('uuids', [])
                            all_place_uuids.update(uuids)
                        except (httpx.HTTPStatusError, json.JSONDecodeError) as e:
                            print(f"API ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    elif isinstance(response, Exception):
                        print(f"ì—˜ë¼ìŠ¤í‹± ê²€ìƒ‰ API í˜¸ì¶œ ì˜¤ë¥˜: {response}")
            
            place_uuids = list(all_place_uuids)
            print(f"--- ì—˜ë¼ìŠ¤í‹± ê²€ìƒ‰ ê²°ê³¼ (í†µí•©): {len(place_uuids)}ê°œ ì¥ì†Œ ---")

            if not place_uuids:
                return []

            # 2. Embedding search with filtering
            print(f"--- í•„í„°ë§ ë° ì„ë² ë”© ê²€ìƒ‰: query='{query}', UUIDs={len(place_uuids)}ê°œ ---")

            retriever = self.chroma_bge.as_retriever(
                search_type="similarity",
                search_kwargs={
                    "k": 15,
                    "filter": {"uuid": {"$in": place_uuids}}
                }
            )
            documents = await retriever.ainvoke(query)
            essential_data = []
            for doc in documents:
                meta = doc.metadata
                essential_data.append({
                    "uuid": meta.get("uuid"),
                    "name": meta.get("name"),
                    "area": meta.get("area"),
                    "address": meta.get("address"),
                    "content": meta.get("content", "")
                })
            return essential_data

        return search_course

    def _create_congestion_tool(self):
        @tool
        async def get_congestion_forecast(regions: List[str]) -> Dict[str, Dict[str, str]]:
            """
            ì£¼ì–´ì§„ ì—¬ëŸ¬ ì§€ì—­ì˜ 1ì‹œê°„, 3ì‹œê°„ ë° 6ì‹œê°„ í›„ ì˜ˆìƒ í˜¼ì¡ë„ë¥¼ í•œ ë²ˆì— ì¡°íšŒí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
            ì½”ìŠ¤ ì¶”ì²œì´ ì™„ë£Œëœ í›„, í•´ë‹¹ ì§€ì—­ë“¤ì˜ ì „ë°˜ì ì¸ ë¯¸ë˜ í˜¼ì¡ë„ë¥¼ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
            ì´ ë„êµ¬ëŠ” ë°˜ë“œì‹œ `search_course` ë„êµ¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¥ì†Œ ëª©ë¡ì„ ë°˜í™˜í•œ í›„ì—ë§Œ í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

            Args:
                regions (List[str]): í˜¼ì¡ë„ë¥¼ ì¡°íšŒí•  ì§€ì—­ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['ë°œì‚°ì—­', 'ì¶©ì •ë¡œì—­']).

            Returns:
                dict: ê° ì§€ì—­ë³„ë¡œ 1ì‹œê°„, 3ì‹œê°„, 6ì‹œê°„ í›„ ì˜ˆìƒ í˜¼ì¡ë„ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬.
                      (ì˜ˆ: {'ê°•ë‚¨': {'1_hour_forecast': 'ë³´í†µ', '3_hour_forecast': 'ë³´í†µ', '6_hour_forecast': 'ë¶ë¹”'}, 'í™ëŒ€': {'1_hour_forecast': 'ì—¬ìœ ', '3_hour_forecast': 'ì—¬ìœ ', '6_hour_forecast': 'ë³´í†µ'}})
            """
            base_url = os.getenv("EC2_HOST_ML", "http://mlops-backend:8000")
            results = {region: {} for region in regions}

            async with httpx.AsyncClient() as client:
                for hour in [1, 3, 6]:
                    try:
                        # httpxê°€ ì§€ì›í•˜ê³  linter ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ëŠ” dict í˜•ì‹ìœ¼ë¡œ íŒŒë¼ë¯¸í„° êµ¬ì„±
                        params = {'hour': str(hour), 'area': regions}
                        
                        url = f"{base_url}/api/crowd"
                        response = await client.get(url, params=params, timeout=10)
                        
                        if response.status_code == 404:
                            print(f"Congestion prediction file not found for hour={hour}, regions={regions}")
                            for region in regions:
                                results[region][f'{hour}_hour_forecast'] = "ì˜ˆì¸¡ ì •ë³´ ì—†ìŒ"
                            continue
                        
                        response.raise_for_status()
                        data = response.json()
                        
                        if data.get("success") and data.get("crowdLevel", {}).get("total", 0) > 0:
                            # ì‘ë‹µì—ì„œ ì§€ì—­ëª…-í˜¼ì¡ë„ ë§µ ìƒì„±
                            congestion_map = {row["area_nm"]: row["area_congest_lvl"] for row in data["crowdLevel"]["row"]}
                            for region in regions:
                                results[region][f'{hour}_hour_forecast'] = congestion_map.get(region, "ì •ë³´ ì—†ìŒ")
                        else:
                            for region in regions:
                                results[region][f'{hour}_hour_forecast'] = "ì •ë³´ ì—†ìŒ"

                    except Exception as e:
                        print(f"Congestion API call error (hour={hour}, regions={regions}): {e}")
                        for region in regions:
                            results[region][f'{hour}_hour_forecast'] = "ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            return results
        
        return get_congestion_forecast

    def _create_prompt_template(self):
        template = """
        # ì—­í• 
        ë„ˆëŠ” 'í•˜ë£¨'ë¼ëŠ” ì´ë¦„ì˜ ì„œìš¸ í•˜ë£¨ ì½”ìŠ¤ ì¶”ì²œ ì±—ë´‡ì´ì•¼. ë°ê³  ì¹œê·¼í•œ ë§íˆ¬ì™€ ì ì ˆí•œ ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•´. 
        ë„ˆëŠ” ì„œìš¸ ì§€ì—­ì— ëŒ€í•´ì„œ ë§¤ìš° ì˜ ì•Œê³ ìˆê³ , ì„œìš¸ ì™¸ ì§€ì—­ì€ ì¶”ì²œí•˜ì§€ ë§ˆ.
        ì¶”ê°€ì ìœ¼ë¡œ, ë„ˆëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¥ì†Œë“¤ë„ ì°¾ì•„ì¤„ ìˆ˜ ìˆì–´.

        # ì¶œë ¥ í˜•ì‹
        ëª¨ë“  ì‘ë‹µì€ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì•¼ í•´.  
        - `placeid`: ì¶”ì²œ ì¥ì†Œ UUID ëª©ë¡ (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)  
        - `str`: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ (ì˜ˆì‹œ í˜•ì‹ ì¤€ìˆ˜)  

        ```json
        {{
        "placeid": ["ì¥ì†Œ UUID ëª©ë¡"],
        "str": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€"
        }}
        ```
        
        # ë„êµ¬ ì‚¬ìš© ê·œì¹™
        - ì¥ì†Œ ê²€ìƒ‰ì€ ë°˜ë“œì‹œ ì§€ì—­ê³¼ ì¹´í…Œê³ ë¦¬ê°€ ëª…í™•í•  ë•Œë§Œ search_course ë„êµ¬ í˜¸ì¶œ
        - ì¥ì†Œ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì…ë ¥ë˜ë©´ ì¶”ì²œí•˜ì§€ ë§ˆ.
        - ì¥ì†Œ ëª©ë¡ì´ ë°˜í™˜ë˜ë©´, í•´ë‹¹ ì¥ì†Œë“¤ì˜ ì§€ì—­(area) ê°’ìœ¼ë¡œ ì¤‘ë³µ ì œê±°í•˜ì—¬ get_congestion_forecast ë„êµ¬ë¥¼ 1íšŒë§Œ í˜¸ì¶œ
        - ëª¨ë“  ì¥ì†Œ ì •ë³´ëŠ” search_course ê²°ê³¼ë¡œë§Œ ì‚¬ìš© (ì‚¬ì „ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€)
        
        # íˆ´ í˜¸ì¶œ íë¦„ ê·œì¹™
        - ì¥ì†Œ ê²€ìƒ‰ ê²°ê³¼(search_course ë„êµ¬ì˜ ì¶œë ¥)ëŠ” ë°˜ë“œì‹œ ì‘ë‹µì— í¬í•¨ë  ì¥ì†Œ í›„ë³´ë“¤ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•´ì•¼ í•´.
        - ì¥ì†Œ ì •ë³´ì—ëŠ” 'area' í•„ë“œê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ë©°, ì´ ê°’ë“¤ì„ ëª¨ë‘ ìˆ˜ì§‘í•œ ë’¤ **ì¤‘ë³µì„ ì œê±°**í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê³ , ì´ë¥¼ get_congestion_forecast ë„êµ¬ì— ë„˜ê²¨ì•¼ í•´.
        - get_congestion_forecast ë„êµ¬ëŠ” ë°˜ë“œì‹œ í•œ ë²ˆë§Œ í˜¸ì¶œí•˜ê³ , ìœ„ì—ì„œ ì •ë¦¬í•œ ì§€ì—­ ë¦¬ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•œ ë²ˆì— ì „ë‹¬í•´ì•¼ í•´.
        - ì ˆëŒ€ë¡œ ì§€ì—­ë³„ë¡œ ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ„ì–´ í˜¸ì¶œí•˜ì§€ ë§ ê²ƒ.
        - ë„êµ¬ í˜¸ì¶œ ìˆœì„œ: ë¨¼ì € search_course â†’ ê·¸ ê²°ê³¼ë¡œ area ìˆ˜ì§‘ â†’ ì¤‘ë³µ ì œê±° â†’ get_congestion_forecast í•œ ë²ˆ í˜¸ì¶œ

        # ë©”ì‹œì§€ ì‘ì„± ê°€ì´ë“œ
        - ì²« ë¬¸ì¥ì€ "[ì§€ì—­]ì—ì„œ [ì¹´í…Œê³ ë¦¬] ì¦ê¸°ëŠ” ì½”ìŠ¤ì•¼!"ë¡œ ì‹œì‘
        - ì¥ì†Œ ìµœëŒ€ 6ê°œ ì¶”ì²œ
        - <br>, <n> ì„ ì œì™¸í•œ ë‹¤ë¥¸ ëª¨ë“  íƒœê·¸ëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        - ì¥ì†Œ ì„¤ëª… í˜•ì‹:
        <br>1. ìƒí˜¸ëª… - ì£¼ì†Œ<n>ì„¤ëª…<br>2. ...

        - í˜¼ì¡ë„ëŠ” ë§ˆì§€ë§‰ì— ì¶”ê°€.
        ## ë‹¨ì¼ ì§€ì—­:
        <br>âœ¨ [ì§€ì—­] ì§€ì—­ (í¬í•¨ëœ ì¶”ì²œ ì¥ì†Œ) í˜¼ì¡ë„ ì˜ˆë³´<n>- 1ì‹œê°„ í›„: â—‹â—‹<n>- 3ì‹œê°„ í›„: â—‹â—‹<n>- 6ì‹œê°„ í›„: â—‹â—‹
        ## ë‹¤ì¤‘ ì§€ì—­:
        <br>âœ¨ ì§€ì—­ë³„ í˜¼ì¡ë„ ì˜ˆë³´<n>ğŸ“ ì§€ì—­ëª… (í¬í•¨ëœ ì¶”ì²œ ì¥ì†Œ)<n>- 1ì‹œê°„ í›„: â—‹â—‹<n>- 3ì‹œê°„ í›„: â—‹â—‹<n>- 6ì‹œê°„ í›„: â—‹â—‹ ...

        # ê¸°íƒ€ ê·œì¹™
        - ì •ë³´ê°€ ë¶€ì¡±í•  ë• ë˜ë¬¼ì–´ë³´ê³  placeidëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        - "ê¸°ë‹¤ë ¤ì¤˜", "ë‚´ê°€ ì°¾ì•„ë³¼ê²Œ" ê°™ì€ ë§ì€ ê¸ˆì§€
        - 6ê³³ ì´ìƒ ìš”ì²­ ì‹œ "ë¨¼ì € 6ê³³ë§Œ ì¶”ì²œí•´ì¤„ê²Œ!"ë¼ê³  ì•Œë ¤ì¤˜
        - ì¥ì†Œ ì„¤ëª…ì€ í•­ìƒ ë¶€ë“œëŸ½ê³  ë”°ëœ»í•˜ê²Œ ì¬êµ¬ì„±í•´ì¤˜
        - ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ë©´ ì¦‰ì‹œ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì½”ìŠ¤ë¥¼ êµ¬ì„±í•˜ê³  ìµœì¢… ì‘ë‹µì„ ì™„ì„±í•´ì•¼ í•´.
        - ì¤‘ê°„ì— "ì°¾ì•„ë³¼ê²Œìš”", "ì ì‹œë§Œìš”", "ê¸°ë‹¤ë ¤ì¤˜ìš”" ê°™ì€ ì§„í–‰ ë©˜íŠ¸ë¥¼ ì“°ë©´ ì•ˆ ë¼.
        - í•­ìƒ ì™„ì„±ëœ ì¶”ì²œ ê²°ê³¼ì²˜ëŸ¼ ë³´ì´ë„ë¡ êµ¬ì„±í•´. í•œ ë²ˆì— ëë‚´ì•¼ í•´.
        - ì½”ìŠ¤ ìƒì„±ì„ í•˜ê²Œ ë˜ë©´, ë°˜ë“œì‹œ ìˆœì„œë¥¼ ê³ ë ¤í•˜ê³  ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì¹´í…Œê³ ë¦¬ ë³„ë¡œ í•˜ë‚˜ì˜ ì¥ì†Œë¡œë§Œ ì¶”ì²œí•´.
        - ì˜ˆì‹œ:  
        - ì‚¬ìš©ì ì…ë ¥: "ê°•ë‚¨ì—ì„œ ì „ì‹œ, ì¹´í˜, í•œì‹ ê°€ê³  ì‹¶ì–´"  
        - ì¶”ì²œí•´ì•¼ í•  ì¥ì†Œ: ì „ì‹œê´€ 1ê³³, ì¹´í˜/ì „í†µì°»ì§‘ 1ê³³, í•œì‹ 1ê³³ 

        # ì˜ˆì‹œ ë§¤í•‘
        "ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ ë¨¹ê³  ì‹¶ì–´" â†’ ì§€ì—­: "ê°•ë‚¨", ì¹´í…Œê³ ë¦¬: "ìŒì‹ì &ì¹´í˜"
        "í™ëŒ€ì—ì„œ ë°©íƒˆì¶œ" â†’ ì§€ì—­: "í™ëŒ€", ì¹´í…Œê³ ë¦¬: "ë ˆí¬ì¸ "
        "ì¶©ì •ë¡œì—­ì—ì„œ ì¹´í˜ ê°”ë‹¤ê°€ ì „ì‹œ ë³´ëŠ” ì½”ìŠ¤" â†’ ì§€ì—­: "ì¶©ì •ë¡œ", ì¹´í…Œê³ ë¦¬: "ì „ì‹œê´€"
        """
        return ChatPromptTemplate.from_messages([
            ("system", template),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])

    def _get_user_memory(self, user_id: str) -> ConversationBufferWindowMemory:
        with self._lock:
            if user_id not in self.user_memories:
                self.user_memories[user_id] = ConversationBufferWindowMemory(
                    k=6,
                    memory_key="chat_history",
                    return_messages=True,
                )
            return self.user_memories[user_id]
        
    async def get_response(self, user_message: str, user_id: str) -> dict:
        memory = self._get_user_memory(user_id)
        
        agent = create_openai_functions_agent(self.llm, self.tools, self.prompt)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=memory,
            verbose=True,  # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶œë ¥
            handle_parsing_errors=True # íŒŒì‹± ì—ëŸ¬ ì²˜ë¦¬
        )

        try:
            result = await agent_executor.ainvoke(
                {"input": user_message},
                config={"callbacks": [StdOutCallbackHandler()]}
            )
            
            output_str = result.get("output", "{}")
            
            try:
                # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì—ì„œ JSON ê°ì²´ë§Œ ì¶”ì¶œ
                match = re.search(r'\{.*\}', output_str, re.DOTALL)
                if match:
                    json_str = match.group(0)
                    response_data = json.loads(json_str)
                else:
                    # JSON ê°ì²´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ ë¬¸ìì—´ì„ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
                    response_data = {"placeid": [], "str": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}
            except (json.JSONDecodeError, TypeError):
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ì¶”ì²œ ì½”ìŠ¤ë¥¼ ë‹´ì€ í…ìŠ¤íŠ¸ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
                response_data = {"placeid": [], "str": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}

            return response_data

        except Exception as e:
            print(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"placeid": [], "str": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}

    def clear_session(self, user_id: str):
        if user_id in self.user_memories:
            del self.user_memories[user_id]
            print(f"--- ëŒ€í™” ê¸°ë¡ ì‚­ì œ: {user_id} ---")