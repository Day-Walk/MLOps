"""
OpenAI ì—°ê²° ì±—ë´‡ ë¼ìš°í„°
ì‹¤ì œ GPT APIì™€ ì—°ê²°, GET ë°©ì‹ + SSE ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
"""
from fastapi import APIRouter, Query, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from typing import Optional
import asyncio
import json
import uuid
from datetime import datetime
import traceback
import os

from app.services.openai_service import OpenAIService
from app.services.place_extractor import PlaceExtractor
from app.schema.chat_schema import ChatResponse, ChatStats

router = APIRouter(prefix="/api", tags=["chatbot"])

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ê¸°ì¡´ê³¼ ë™ì¼)
openai_service = OpenAIService(os.getenv("OPENAI_API_KEY"))
place_extractor = PlaceExtractor()
active_sessions = {}

@router.get("/chat", response_model=ChatResponse)
async def chat_endpoint(
    message: str = Query(..., description="ì‚¬ìš©ì ë©”ì‹œì§€"),
    session_id: Optional[str] = Query(None, description="ì„¸ì…˜ ID")
):
    """
    OpenAI ì±—ë´‡ API (GET ë°©ì‹)
    ì‘ë‹µ: {"str1": "GPT ë‹µë³€", "placeid": ["uuid1", "uuid2"], "str2": null}
    """
    if not openai_service:
        return JSONResponse(
            status_code=503,
            content={
                "str1": "ì£„ì†¡í•©ë‹ˆë‹¤. ì±—ë´‡ ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "placeid": None,
                "str2": None
            }
        )
    
    try:
        session_id = session_id or str(uuid.uuid4())
        active_sessions[session_id] = {
            "start_time": datetime.now(), 
            "type": "sync"
        }
        
        print(f"ğŸ“ ì±„íŒ… ìš”ì²­: {message} (ì„¸ì…˜: {session_id})")
        print(f"ğŸ”„ í™œì„± ì„¸ì…˜ ìˆ˜: {len(active_sessions)}")
        
        # OpenAI API í˜¸ì¶œ
        gpt_response = await openai_service.get_chat_completion(message)
        
        # ì¥ì†Œ ID ì¶”ì¶œ
        place_ids = place_extractor.extract_place_ids_from_text(gpt_response)
        
        # ì»¤ìŠ¤í…€ ì‘ë‹µ í˜•ì‹
        response = {
            "str1": gpt_response,
            "placeid": place_ids if place_ids else None,
            "str2": None
        }
        
        # ì„¸ì…˜ ì •ë¦¬
        active_sessions.pop(session_id, None)
        
        return JSONResponse(content=response)
        
    except Exception as e:
        print(f"âŒ ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        active_sessions.pop(session_id, None)
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={
                "str1": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "placeid": None,
                "str2": None
            }
        )

@router.get("/chat/stream")
async def chat_stream_endpoint(
    message: str = Query(..., description="ì‚¬ìš©ì ë©”ì‹œì§€"),
    session_id: Optional[str] = Query(None, description="ì„¸ì…˜ ID")
):

    """
    ì •í•´ì§„ í˜•ì‹ SSE ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ API
    ì™„ì„±ëœ ë©”ì‹œì§€ë¥¼ {"str1": "", "placeid": [], "str2": ""} í˜•ì‹ìœ¼ë¡œ ì „ì†¡
    """
    session_id = session_id or str(uuid.uuid4())
    active_sessions[session_id] = {
        "start_time": datetime.now(), 
        "type": "structured_stream"
    }
    
    print(f"ğŸ”„ êµ¬ì¡°í™” ìŠ¤íŠ¸ë¦¼ ìš”ì²­: {message} (ì„¸ì…˜: {session_id})")
    
    async def generate_structured_stream():
        try:
            # 1. OpenAIì—ì„œ ì™„ì „í•œ ì‘ë‹µ ë°›ê¸° (ë‚´ë¶€ì ìœ¼ë¡œëŠ” ì¼ë°˜ í˜¸ì¶œ)
            gpt_response = await openai_service.get_chat_completion(message)
            
            # 2. ì¥ì†Œ ID ì¶”ì¶œ
            place_ids = place_extractor.extract_place_ids_from_text(gpt_response)
            
            # 3. ì‹œì‘ ë©”ì‹œì§€ (ì²˜ë¦¬ ì‹œì‘ ì•Œë¦¼)
            start_message = {
                "type": "start",
                "str1": "ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "placeid": None,
                "str2": None,
                "session_id": session_id
            }
            yield f"data: {json.dumps(start_message, ensure_ascii=False)}\n\n"
            
            # 4. ì•½ê°„ì˜ ì§€ì—° (ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜)
            await asyncio.sleep(1)
            
            # 5. ì§„í–‰ ìƒí™© ë©”ì‹œì§€ (ì„ íƒì‚¬í•­)
            progress_message = {
                "type": "progress", 
                "str1": "ì¥ì†Œ ì •ë³´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...",
                "placeid": None,
                "str2": None,
                "session_id": session_id
            }
            yield f"data: {json.dumps(progress_message, ensure_ascii=False)}\n\n"
            
            await asyncio.sleep(1)
            
            # 6. ìµœì¢… ì™„ì„±ëœ ì‘ë‹µ (ì •í•´ì§„ í˜•ì‹)
            final_message = {
                "type": "complete",
                "str1": gpt_response,
                "placeid": place_ids if place_ids else None,
                "str2": None,  # í•„ìš”ì‹œ ì¶”ê°€ ì •ë³´
                "session_id": session_id,
                "timestamp": datetime.now().isoformat()
            }
            yield f"data: {json.dumps(final_message, ensure_ascii=False)}\n\n"
            
            # 7. ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹ í˜¸
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            print(f"âŒ êµ¬ì¡°í™” ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            error_message = {
                "type": "error",
                "str1": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "placeid": None,
                "str2": None,
                "session_id": session_id
            }
            yield f"data: {json.dumps(error_message, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"
        
        finally:
            # ì„¸ì…˜ ì •ë¦¬
            active_sessions.pop(session_id, None)
    
    return StreamingResponse(
        generate_structured_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "X-Session-ID": session_id,
            "X-Stream-Type": "structured"
        }
    )
@router.get("/chat/clear")
async def clear_chat(session_id: str = Query(..., description="ì´ˆê¸°í™”í•  ì„¸ì…˜ ID")):
    """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (GET ìš”ì²­)"""
    try:
        # í™œì„± ì„¸ì…˜ì—ì„œ ì œê±°
        removed = active_sessions.pop(session_id, None)
        
        return {
            "success": True, 
            "message": f"ì„¸ì…˜ {session_id} ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "was_active": removed is not None
        }
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/chat/health")
async def chat_health_check():
    """ì±—ë´‡ í—¬ìŠ¤ì²´í¬"""
    try:
        if openai_service:
            openai_connected = await openai_service.test_connection()
        else:
            openai_connected = False
        
        return {
            "status": "healthy" if openai_connected else "unhealthy",
            "openai_connected": openai_connected,
            "service": "chatbot",
            "active_sessions": len(active_sessions)
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "openai_connected": False
        }

@router.get("/chat/stats")
async def get_chat_stats():
    """ì‹¤ì‹œê°„ í†µê³„ (ë™ì‹œ ì ‘ì† ëª¨ë‹ˆí„°ë§)"""
    return {
        "active_sessions": len(active_sessions),
        "sessions_detail": {
            session_id: {
                "start_time": session_data["start_time"].isoformat(),
                "type": session_data["type"],
                "duration_seconds": (datetime.now() - session_data["start_time"]).total_seconds()
            }
            for session_id, session_data in active_sessions.items()
        },
        "total_sync_sessions": len([s for s in active_sessions.values() if s["type"] == "sync"]),
        "total_stream_sessions": len([s for s in active_sessions.values() if s["type"] == "stream"])
    }
